% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/solve_slope.R
\name{solve_slope}
\alias{solve_slope}
\title{Sorted L1 solver}
\usage{
solve_slope(X, y, lambda, initial = NULL, max_iter = 10000,
  grad_iter = 20, opt_iter = 1, tol_infeas = 1e-06,
  tol_rel_gap = 1e-06)
}
\arguments{
\item{X}{an \eqn{n}-by-\eqn{p} matrix}

\item{y}{a vector of length \eqn{n}}

\item{lambda}{vector of length \eqn{p}, sorted in decreasing order}

\item{initial}{initial guess for \eqn{w}}

\item{max_iter}{maximum number of iterations in the gradient descent}

\item{grad_iter}{number of iterations between gradient updates}

\item{opt_iter}{number of iterations between checks for optimality}

\item{tol_infeas}{tolerance for infeasibility}

\item{tol_rel_gap}{tolerance for relative gap between primal and dual
problems}
}
\value{
The solution vector \eqn{w}
}
\description{
Solves the sorted L1 penalized regression problem: given a matrix \eqn{X},
a vector \eqn{y}, and a decreasing vector \eqn{\lambda}, find the vector
\eqn{w} minimizing
\deqn{\frac{1}{2}\Vert Xw - y \Vert_2^2 +
      \sum_{i=1}^p \lambda_i |w|_{(i)}.}
}
\details{
This optimization problem is convex and is solved using an
accelerated proximal gradient descent method.
}
